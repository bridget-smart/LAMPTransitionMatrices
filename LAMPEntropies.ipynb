{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Preamble for most code and jupyter notebooks\n",
    "@author: bridgetsmart\n",
    "@notebook date: 6 Jun 2022\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "import math, string, re, pickle, json, time, os, sys, datetime, itertools\n",
    "from ProcessEntropy.SelfEntropy import self_entropy_rate\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set panda's options\n",
    "pd.set_option(\"display.max_rows\", 40)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "# Graphics for thesis\n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "params = {\n",
    "    'axes.labelsize': 10,\n",
    "    'font.size': 10,\n",
    "    'legend.fontsize': 8,\n",
    "    'xtick.labelsize': 8,\n",
    "    'ytick.labelsize': 8,\n",
    "    'figure.figsize': [5.3, 3.34], # Thesis width\n",
    "    'figure.dpi' : 72, \n",
    "    'font.family': \"serif\",\n",
    "    'text.usetex': False, # Use LaTeX when desired\n",
    "    }\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "# Set packages to autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit regular Markov Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_to_markov(data):\n",
    "    # need to map all to a 0,n-1 alphabet\n",
    "    # then use the markov chain to get the probabilities\n",
    "\n",
    "    # number of states\n",
    "    states = [y for x in data for y in x]\n",
    "\n",
    "    # first, get the alphabet\n",
    "    alphabet = list(set(states))\n",
    "    alphabet.sort()\n",
    "    n = len(alphabet)\n",
    "    # now, map the data to the alphabet\n",
    "    data_mapped = np.array([[alphabet.index(y) for y in x] for x in data])\n",
    "    states = [alphabet.index(x) for x in states]\n",
    "    # get all one steps    \n",
    "    one_step_trans = [(x[i], x[i+1]) for x in data_mapped for i in range(len(x)-1)]\n",
    "\n",
    "    # transition matrix\n",
    "    A = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            A[i, j] = one_step_trans.count((i, j))\n",
    "\n",
    "    # # initial distribution\n",
    "    # pi = np.zeros(n)\n",
    "    # for i in range(n):\n",
    "    #     pi[i] = states.count(i)\n",
    "\n",
    "    \n",
    "    # normalize\n",
    "    A /= A.sum(axis=1)[:, None]\n",
    "\n",
    "    return A, n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get entropy from transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ent(pi,A,n):\n",
    "    # get the entropy\n",
    "    ent = 0\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if A[i,j] ==0:\n",
    "                pass\n",
    "            else:\n",
    "                ent += - pi[i]*A[i,j]*math.log(A[i,j])\n",
    "    return ent    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get entropy estimates from LAMP fit\n",
    "def get_stationary(A):\n",
    "    e_vals, eig_vecs = np.linalg.eig(A.T) # gets left e vectors\n",
    "    l = np.where(abs(e_vals-1) == np.min(abs(e_vals-1)))[0][0]\n",
    "    # get real component\n",
    "    v = eig_vecs[:,l].real\n",
    "    return v/sum(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get shannon entropy + return all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ent_est(data):\n",
    "    s = [y for x in data for y in x]\n",
    "    #### do once by appending all\n",
    "    print('getting estimate 1...')\n",
    "    est1 = self_entropy_rate(s)\n",
    "\n",
    "    #### do by averaging each path\n",
    "    print('getting estimate 2...')\n",
    "    est2 = np.mean([self_entropy_rate(x) for x in tqdm(data)])\n",
    "\n",
    "    # fit markov\n",
    "    print('getting estimate 3...')\n",
    "    A,n = fit_to_markov(data)\n",
    "    pi = get_stationary(A)\n",
    "    est3 = get_ent(pi,A,n)\n",
    "\n",
    "    #### shannon estimator\n",
    "    print('getting estimate 4...')\n",
    "    est4 = np.sum(-pi*np.log(pi))\n",
    "\n",
    "    return est1, est2, est3, est4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trans(fn):\n",
    "    # read in transition matrix\n",
    "    with open(data_path+fn, 'r') as f:\n",
    "        lamp_transitions = np.array([y.replace(\"\\n\",\"\").split(',') for y in f.readlines()])\n",
    "        n_lamp = np.max(list(set([int(x) for x in lamp_transitions[:,2]] + [int(x) for x in lamp_transitions[:,1]])))+1\n",
    "        lamp_A = np.zeros((n_lamp,n_lamp))\n",
    "        for r in lamp_transitions:\n",
    "            lamp_A[int(r[1]),int(r[2])] = float(r[0]) # value\n",
    "        return lamp_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikispedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamp_A = get_trans(\"wiki_transition_matrix.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "with open(data_path + 'wiki_paths.txt', 'r') as f:\n",
    "    data = [x.replace(\"\\n\",\"\").split(\";\") for x in f.readlines()]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all estimates\n",
    "\n",
    "e1,e2,e3,e4 = ent_est(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brightkite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## last-fm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f00d211e9e60e25303b946dd7a0968412ca29119ce6c421f60b0be0890f3af31"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('playground')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
